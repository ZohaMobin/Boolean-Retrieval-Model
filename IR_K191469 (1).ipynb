{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d6d7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53e502ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80dc2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c98c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords():  #list all stop words .\n",
    "  stopword=[]\n",
    "  f=open(\"/Users/zohamobin/Downloads/Stopword-List (1).txt\",\"r\")\n",
    "  stopwordlist=f.readlines()\n",
    "  f.close()\n",
    "  for l in stopwordlist:\n",
    "     stopword=stopword+l.split()\n",
    "  return(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66563d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_tokenize(speech_text):\n",
    "\n",
    "    \n",
    "    clean_words = re.sub(r'[^\\w\\s]','',speech_text) #removed punctuation and brackets\n",
    "    words = clean_words.split() \n",
    "    words = [word.lower() for word in words] #lower cased\n",
    "    words = list(set(words)) #Duplicates Removed\n",
    "    \n",
    "    stopword=read_stopwords()\n",
    "    words = [word for word in words if word not in stopword] #Remove Stop words\n",
    "    \n",
    "    ps_word = PorterStemmer() #Stemming\n",
    "    stemmed_word = [ps_word.stem(word) for word in words]\n",
    "      \n",
    " \n",
    "    return stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81e4f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=''\n",
    "Inverted_Index={}\n",
    "position_Index={}\n",
    "#inverted_index={}\n",
    "speech_text=''\n",
    "path = \"/Users/zohamobin/Documents/abstracts/Abstracts\"\n",
    "os.chdir(path)\n",
    "for i in os.listdir():\n",
    "         pos=-1\n",
    "         f = open(i, \"r\", encoding='latin-1')\n",
    "         speech_text = f.read()\n",
    "         \n",
    "         f.close()\n",
    "         total_words = speech_tokenize(speech_text) \n",
    "         #total_words.append(clean)\n",
    "         for word in total_words: \n",
    "            pos=pos+1  \n",
    "            if word not in Inverted_Index: #Create Inverted Index\n",
    "                Inverted_Index[word]=[]\n",
    "            if word in Inverted_Index:\n",
    "                Inverted_Index[word].append(i)\n",
    "                \n",
    "            if word not in position_Index:  #Create Positional Index\n",
    "                 position_Index[word] = {i : [pos]}\n",
    "            elif i in position_Index:\n",
    "                position_Index[word][i].append(pos)\n",
    "            else:\n",
    "                position_Index[word][i] = [pos]   \n",
    "           \n",
    "                \n",
    "               \n",
    "         #print(Inverted_Index[word])\n",
    "     \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a777c1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5854"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Inverted_Index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad461a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postfix(infix_tokens):\n",
    " \n",
    " #precendence initialization\n",
    "    precedence = {}\n",
    "    precedence['not'] = 3\n",
    "    precedence['and'] = 2\n",
    "    precedence['or'] = 1\n",
    "    output = []\n",
    "    op_stack = []\n",
    " \n",
    " #creating postfix expression\n",
    "    for token in infix_tokens:\n",
    "#         print(token)\n",
    " \n",
    "        if (token in precedence):\n",
    "#             operator_stack.append(token)\n",
    "            if (op_stack):\n",
    "                current_operator = op_stack[-1]\n",
    "                while (op_stack and precedence[current_operator] > precedence[token]):\n",
    "                    output.append(op_stack.pop())\n",
    "                    if (op_stack):\n",
    "                        current_operator = op_stack[-1]\n",
    "            \n",
    "            op_stack.append(token)\n",
    "        \n",
    "        else:\n",
    "            output.append(token.lower())\n",
    " \n",
    " \n",
    "    while (op_stack):\n",
    "        output.append(op_stack.pop())\n",
    "    return output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd3b9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AND two words\n",
    "def AND_OP(word1,word2):\n",
    "    if ((word1) and (word2)):\n",
    "        return set(word1).intersection(word2)\n",
    "    else:\n",
    "        return set()\n",
    "     \n",
    "#OR two words\n",
    "def OR_OP(word1,word2):\n",
    "    return set(word1).union(word2)\n",
    "   \n",
    "#NOT two words\n",
    "def NOT_OP(a,doc):\n",
    "    return set(doc).symmetric_difference(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db4e1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(q,inverted_index):\n",
    "\n",
    "    query = []\n",
    "    \n",
    "    for ele in q.split(' '):\n",
    "        ps_word = PorterStemmer() #Stemming\n",
    "        ele=ps_word.stem(ele)\n",
    "        query.append(ele.lower())\n",
    "#     print(query)\n",
    "#     for i in range(0,len(query)):\n",
    "#         if ( query[i] == 'and' or query[i] == 'or' or query[i] == 'not'):\n",
    "# #             query[i] = query[i].upper()\n",
    "    results_stack = []\n",
    "    postfix_queue = postfix(query)\n",
    "    print(postfix_queue)\n",
    "\n",
    "    #evaluating postfix query expression\n",
    "    for i in postfix_queue:\n",
    "        if ( i!= 'and' and i!= 'or' and i!= 'not'):\n",
    "            i = i.lower()\n",
    "            i = inverted_index.get(i)\n",
    "            results_stack.append(i)\n",
    "        elif (i=='or'):\n",
    "            a = results_stack.pop()\n",
    "            b = results_stack.pop()\n",
    "            results_stack.append(OR_OP(a,b))\n",
    "        elif (i=='and'):\n",
    "            a = results_stack.pop()\n",
    "            b = results_stack.pop()\n",
    "            results_stack.append(AND_OP(a,b))\n",
    "        elif (i == 'not'):\n",
    "            a = results_stack.pop()\n",
    "            results_stack.append(NOT_OP(a,ls))\n",
    "            \n",
    "    return results_stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20ea39d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'seri', 'and', 'classif', 'or']\n",
      "{'55.txt', '353.txt', '38.txt', '357.txt', '193.txt', '174.txt', '442.txt', '313.txt', '295.txt', '56.txt', '350.txt', '341.txt', '33.txt', '123.txt', '303.txt', '387.txt', '377.txt', '85.txt', '432.txt', '345.txt', '147.txt', '34.txt', '305.txt', '283.txt', '113.txt', '182.txt', '277.txt', '438.txt', '51.txt', '375.txt', '397.txt', '59.txt', '76.txt', '239.txt', '158.txt', '54.txt', '60.txt', '286.txt', '126.txt', '371.txt', '16.txt', '73.txt', '187.txt', '168.txt', '289.txt', '302.txt', '236.txt', '252.txt', '64.txt', '237.txt', '439.txt', '215.txt', '256.txt', '273.txt', '424.txt', '63.txt', '71.txt', '198.txt', '80.txt', '43.txt', '384.txt', '122.txt', '165.txt', '425.txt', '265.txt', '58.txt', '140.txt', '208.txt', '385.txt', '354.txt', '177.txt', '287.txt', '235.txt', '234.txt', '67.txt', '210.txt', '272.txt', '405.txt', '202.txt', '395.txt', '352.txt', '299.txt', '421.txt', '240.txt', '111.txt', '378.txt', '24.txt', '164.txt', '348.txt', '46.txt', '6.txt', '248.txt', '45.txt', '4.txt', '77.txt', '369.txt', '249.txt', '22.txt', '128.txt', '95.txt', '328.txt', '106.txt', '107.txt', '143.txt', '99.txt', '40.txt', '197.txt', '386.txt', '247.txt', '9.txt', '427.txt', '445.txt', '316.txt', '125.txt', '245.txt', '261.txt', '229.txt', '98.txt', '175.txt', '280.txt', '334.txt', '94.txt', '404.txt', '176.txt', '10.txt', '167.txt', '338.txt', '321.txt', '120.txt', '317.txt', '228.txt', '213.txt', '75.txt', '382.txt', '259.txt', '49.txt', '238.txt', '268.txt', '173.txt', '66.txt', '220.txt', '84.txt', '171.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(process_query('time AND series OR classification',Inverted_Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b636b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aab2386f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['289.txt',\n",
       " '262.txt',\n",
       " '101.txt',\n",
       " '101.txt',\n",
       " '14.txt',\n",
       " '14.txt',\n",
       " '28.txt',\n",
       " '277.txt',\n",
       " '261.txt',\n",
       " '249.txt',\n",
       " '264.txt',\n",
       " '13.txt',\n",
       " '13.txt',\n",
       " '106.txt',\n",
       " '106.txt',\n",
       " '310.txt',\n",
       " '12.txt',\n",
       " '12.txt',\n",
       " '265.txt',\n",
       " '267.txt',\n",
       " '273.txt',\n",
       " '273.txt',\n",
       " '38.txt',\n",
       " '38.txt',\n",
       " '139.txt',\n",
       " '105.txt',\n",
       " '313.txt',\n",
       " '138.txt',\n",
       " '11.txt',\n",
       " '266.txt',\n",
       " '76.txt',\n",
       " '76.txt',\n",
       " '89.txt',\n",
       " '177.txt',\n",
       " '177.txt',\n",
       " '348.txt',\n",
       " '360.txt',\n",
       " '412.txt',\n",
       " '412.txt',\n",
       " '162.txt',\n",
       " '176.txt',\n",
       " '75.txt',\n",
       " '174.txt',\n",
       " '174.txt',\n",
       " '389.txt',\n",
       " '376.txt',\n",
       " '411.txt',\n",
       " '213.txt',\n",
       " '207.txt',\n",
       " '64.txt',\n",
       " '64.txt',\n",
       " '373.txt',\n",
       " '373.txt',\n",
       " '400.txt',\n",
       " '170.txt',\n",
       " '170.txt',\n",
       " '212.txt',\n",
       " '403.txt',\n",
       " '99.txt',\n",
       " '167.txt',\n",
       " '211.txt',\n",
       " '354.txt',\n",
       " '368.txt',\n",
       " '368.txt',\n",
       " '369.txt',\n",
       " '355.txt',\n",
       " '382.txt',\n",
       " '180.txt',\n",
       " '237.txt',\n",
       " '237.txt',\n",
       " '6.txt',\n",
       " '141.txt',\n",
       " '141.txt',\n",
       " '155.txt',\n",
       " '155.txt',\n",
       " '83.txt',\n",
       " '380.txt',\n",
       " '343.txt',\n",
       " '343.txt',\n",
       " '425.txt',\n",
       " '425.txt',\n",
       " '154.txt',\n",
       " '51.txt',\n",
       " '51.txt',\n",
       " '193.txt',\n",
       " '92.txt',\n",
       " '391.txt',\n",
       " '408.txt',\n",
       " '346.txt',\n",
       " '151.txt',\n",
       " '44.txt',\n",
       " '44.txt',\n",
       " '46.txt',\n",
       " '46.txt',\n",
       " '184.txt',\n",
       " '153.txt',\n",
       " '153.txt',\n",
       " '147.txt',\n",
       " '436.txt',\n",
       " '378.txt',\n",
       " '387.txt',\n",
       " '185.txt',\n",
       " '280.txt',\n",
       " '294.txt',\n",
       " '121.txt',\n",
       " '121.txt',\n",
       " '109.txt',\n",
       " '322.txt',\n",
       " '108.txt',\n",
       " '134.txt',\n",
       " '134.txt',\n",
       " '21.txt',\n",
       " '295.txt',\n",
       " '281.txt',\n",
       " '283.txt',\n",
       " '283.txt',\n",
       " '268.txt',\n",
       " '268.txt',\n",
       " '23.txt',\n",
       " '136.txt',\n",
       " '136.txt',\n",
       " '334.txt',\n",
       " '447.txt',\n",
       " '137.txt',\n",
       " '137.txt',\n",
       " '22.txt',\n",
       " '241.txt',\n",
       " '282.txt',\n",
       " '282.txt',\n",
       " '292.txt',\n",
       " '279.txt',\n",
       " '279.txt',\n",
       " '245.txt',\n",
       " '26.txt',\n",
       " '325.txt',\n",
       " '126.txt',\n",
       " '27.txt',\n",
       " '250.txt',\n",
       " '285.txt',\n",
       " '246.txt',\n",
       " '252.txt',\n",
       " '19.txt',\n",
       " '333.txt',\n",
       " '333.txt',\n",
       " '125.txt',\n",
       " '30.txt']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inverted_Index.get('featur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46e3e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrasal_query(w,Inverted_Index,Position_Index):  #This function will solve bi word phrasal query\n",
    "    result=[] \n",
    "    \n",
    "    for ele in w.split(' '):\n",
    "        ps_word = PorterStemmer() #Stemming\n",
    "        ele=ps_word.stem(ele)\n",
    "        result.append(ele.lower())\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,len(w)):\n",
    "       \n",
    "        if ( (w[0] in Inverted_Index) and (w[1] in Inverted_Index) ):        \n",
    "           for i in range (0,56):\n",
    "              if ( (str(i) in Inverted_Index[w[0]]) and (str(i) in Inverted_Index[w[1]]) ):\n",
    "                  left=0\n",
    "                  right=0\n",
    "                  while((left<(len(Position_Index[w[0]][str(i)]))) and (right<(len(Position_Index[w[1]][str(i)])))):\n",
    "                      if(int(Position_Index[w[1]][str(i)][right])-int(Position_Index[w[0]][str(i)][left])==1):\n",
    "                          result.append(str(i))\n",
    "                          break\n",
    "                      elif (int(Position_Index[w[1]][str(i)][right])>int(Position_Index[w[0]][str(i)][left])):\n",
    "                          left=left+1\n",
    "                      else:\n",
    "                          right=right+1\n",
    "\n",
    "    return(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "642fb0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'and', 'seri', 'and', 'classif']\n"
     ]
    }
   ],
   "source": [
    "print(phrasal_query('time AND series AND classification',Inverted_Index,position_Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "711988db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximity_query(w,Inverted_Index,Position_Index):  #This function will solve proximity query\n",
    "    result=[]\n",
    "    k=w[-1]\n",
    "    \n",
    "    for ele in w.split(' '):\n",
    "        ps_word = PorterStemmer() #Stemming\n",
    "        ele=ps_word.stem(ele)\n",
    "        result.append(ele.lower())\n",
    "    \n",
    "    \n",
    "     \n",
    "    for i in range(0,len(w)):\n",
    "    \n",
    "        if ( (w[0] in Inverted_Index) and (w[1] in Inverted_Index) ):        \n",
    "           for i in range (0,56):\n",
    "              if ( (str(i) in Inverted_Index[w[0]]) and (str(i) in Inverted_Index[w[1]]) ):\n",
    "                  left=0\n",
    "                  right=0\n",
    "                  while((left<(len(Position_Index[w[0]][str(i)]))) and (right<(len(Position_Index[w[1]][str(i)])))):\n",
    "                      if(int(Position_Index[w[1]][str(i)][right])-int(Position_Index[w[0]][str(i)][left])==int(k)+1):\n",
    "                          result.append(str(i))\n",
    "                          break\n",
    "                      elif (int(Position_Index[w[1]][str(i)][right])>int(Position_Index[w[0]][str(i)][left])):\n",
    "                          left=left+1\n",
    "                      else:\n",
    "                          right=right+1\n",
    "          \n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7397331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neural', 'inform', '/2']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d132f7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query\n",
      "image AND restoration\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter Query\")\n",
    "query=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17997fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imag', 'restor', 'and']\n",
      "{'375.txt', '359.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(process_query(query,Inverted_Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1c9ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter  #Ignore the GUI\n",
    "from tkinter import ttk\n",
    "\n",
    "window=tkinter.Tk()\n",
    "window.title(\"Boolean Retrieval Model\")\n",
    "\n",
    "labelone=ttk.Label(window,text=\"Enter Query : \")\n",
    "labelone.grid(row = 0, column = 0)\n",
    "\n",
    "labeltwo=ttk.Label(window,text=\"Result of Query by Boolean Retrieval Model is : \")\n",
    "labeltwo.grid(row = 2, column = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5f57b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=tkinter.StringVar()\n",
    "\n",
    "\n",
    "userentry=ttk.Entry(window,width=50,textvariable = inp)\n",
    "userentry.grid(row = 0 , column = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ad5f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action():\n",
    "   \n",
    "   result=process_query(inp.get(),Inverted_Index)\n",
    "   if(len(result)==0):\n",
    "       labelthree=ttk.Label(window,text='No Result Found .')\n",
    "   else:\n",
    "       labelthree=ttk.Label(window,text=result)\n",
    "   labelthree.grid(row = 2, column = 1)\n",
    "\n",
    "   labelthree.after(10000,lambda: labelthree.destroy())\n",
    "\n",
    "\n",
    "   btn = ttk.Button(window,text=\"Submit\",command=action)\n",
    "   btn.grid(row = 0,column = 2)\n",
    "\n",
    "\n",
    "\n",
    "   window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328bc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
